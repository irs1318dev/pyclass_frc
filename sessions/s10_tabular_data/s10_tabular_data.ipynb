{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](../../index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRC Analytics with Python - Session 09\n",
    "# Tabular Data\n",
    "**Last Updated: 20 December 2020**\n",
    "\n",
    "## I. Introduction\n",
    "Tabular data is data that is organized into rows and columns. It's everywhere -- in newspapers and magazines, on websites, in computer databases, and in Microsoft Excel files. Evaluating and manipulating tabular data is an essential skill for any analyst.\n",
    "\n",
    "So far we've experimented with lists, tuples, and dictionaries. These data structures are indispensable, but they are not optimal for working with tables. In this session we will review several techniques and tools for working with tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Comma Separated Value (CSV) Files\n",
    "### A. CSV File Structure\n",
    "Tabular data is often stored in comma separated value (CSV) files. CSV files are text files that use commas and newline characters (I'll explain what those are shortly) to organize the contents of the file into a table. Let's look at an example. The `space.csv` file contains information on 4,324 space launches, starting with the launch of the the Sputnik spacecraft by the Soviet Union in 1957. The dataset is available on the [Kaggle website](https://www.kaggle.com/agirlcoding/all-space-missions-from-1957). The Python code below opens the file and displays the first five lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a text file and print the first five lines\n",
    "# Don't worry if you don't understand all of this code.\n",
    "with open(\"space.csv\", \"rt\", encoding=\"UTF-8\") as csv_file:\n",
    "    for row in range(5):\n",
    "        print(csv_file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row of text contains the column headings, with each column separated by a comma. The subsequent rows contain the data, with one row for each space launch. The rows are separated from each other with a newline character.\n",
    "\n",
    "Commas are also used for separation in the data rows, but it's a bit difficult to keep track of what text belongs to which column. Many of the data values contain commas inside the data. For example, the second column in the first row contains the value *\"LC-39A, Kennedy Space Center, Florida, USA\"*. The commas within quotation marks are part of the data and are not used for column separation.\n",
    "\n",
    "CSV files are popular because they are simple to create and can be opened and read with any text editor. Still, the content can be tedious to read. All of the values within a row are smashed together and the columns in the data rows do not line up with the column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Python CSV Module\n",
    "We saw earlier how we can use a built-in Python function like `open()` to read data from a CSV file on disk, but the results can be difficult to read. The Python Standard Library has a `csv` module that makes things a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "space_csv = []\n",
    "with open(\"space.csv\", \"rt\", encoding=\"UTF-8\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    for row in reader:\n",
    "        space_csv.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_csv[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `csv` module converts every row of the CSV file to a Python list. We appended every row to an outer list, to create a lists of lists, or a nested list. Each value is now put on its own row. We can even extract individual values from the nested list. For example, to get the third element of the third row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_csv[2][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to figure out how many space launches occurred in China on Wednesdays since the year 2000? That would require us to write several lines of code to read through all of the rows of data and count the applicable launches. Fortunately Python has a better tool for working with tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Pandas Package\n",
    "The *Pandas* package is an excellent tool for working with tabular data. Pandas is not included by default when installing Python, but it can easily be installed by running the command `conda install pandas`.\n",
    "\n",
    "Pandas has so many features that it would take a book to explain them all. This session omits several important Pandas topics, such as timeseries data and multi-level indices. Students are encouraged to become familiar with the official Pandas documentation, which is located here: https://pandas.pydata.org/pandas-docs/stable/index.html. The remaining sections of this notebook contain links to applicable portions of the documentation, which provide additional information on each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Getting Started\n",
    " Let's see how our space data looks when we use Pandas to view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "space_df = pd.read_csv(\"space.csv\", thousands=\",\")\n",
    "space_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that is much better. All of the data lines up with the column headers. Pandas even adds row numbers and shades alternate rows to make everything easy to read. And we did everything in three short lines of code:\n",
    "* The first line imports the pandas module and renames it `pd`.\n",
    "* The next line reads the CSV file and creates a `DataFrame` object.\n",
    "* The final line displays the `DataFrame` object. The `.head()` method causes only the first five lines to be displayed. You can customize the number of lines displayed with .head() by putting the number in the parenthesis.\n",
    "\n",
    "By the way, the package isn't named *Pandas* because the developers really like pandas (but who doesn't like pandas?). *Pandas* is short for *panel data*. Panel data is common in the social sciences. It is multi-dimensional data on on multiple entities, with measurements taken at several points in time. For example, suppose we're conducting a study on family income over time. We might collect multiple pieces of data on each family, such as income, number of children, education level of parents, age of parents, whether they own their home, etc. If we collect such information on 500 families, and then update the information every year for five years, we have panel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `len()` function can be used with dataframes to get the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using len() with DataFrames\n",
    "len(space_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas `DataFrame` objects have a `shape` attribute that contains a two-element tuple (immutable lists). The first element is the number of rows and the second is the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows and columns:\", space_df.shape)\n",
    "print(\"Just the number of columns:\", space_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Intro to Dataframes](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/01_table_oriented.html)\n",
    "* [Read and Write Tabular Data](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/02_read_write.html)\n",
    "* [10 Minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "* [Essential Functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Easy Pandas Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. III.1** The `.head()` method will accept an integer argument that represents the number of rows to display. Display the first eight rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. III.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. III.2** There is also a `tail()` method that will display the last few rows of a dataframe. Display the last 4 rows of the `space_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. III.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Pandas Data Types\n",
    "Pandas provides two different types of data structures: `Series` and `DataFrame`. \n",
    "\n",
    "#### DataFrame\n",
    "What type of data structure is the `space_df` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of object is space_df?\n",
    "type(space_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `space_df` object is an object of type [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe). Most `DataFrame` objects are two-dimensional with rows and columns. `DataFrames` can be modified to contain data with three or more dimensions, such as panel data, but we won't bother with that in this course.\n",
    "\n",
    "Pay attention to the capitalization of `DataFrame` (capital F). We're using the word \"dataframe\" a couple different ways. A dataframe is a two-dimensional data structure that can be found in Python, [R](https://en.wikipedia.org/wiki/R_(programming_language) (a language for statistical analysis), and [Julia](https://en.wikipedia.org/wiki/Julia_(programming_language) (a relatively new language that is good for numerical analysis). A `DataFrame`, on the other hand, is a Python data type provided by the *Pandas* package.\n",
    "\n",
    "#### Series\n",
    "The following code extracts a single column from the `space_df` dataframe and displays its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.Series data type\n",
    "datum_series = space_df.Datum.head(6)  # Extract a single column(named Datum in this case) and display top six rows\n",
    "print(datum_series)\n",
    "type(datum_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how we extracted a single column from the `DataFrame` by appending a period and its name to the name of the `DataFrame`? Extracting a single column results in a Pandas [`Series`](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#series) object. A `Series` is similar to a list, but with some differences:\n",
    "* Unlike a Python list, all elements of a `Series` must have the same data type. The *Datum* column's type is *object*, which is the type Pandas uses for strings.\n",
    "* The contents of a Pandas `Series` are stored in memory more efficiently than lists. Because of this, calculations on `Series` objects are often faster than equivalent calculations on lists.\n",
    "\n",
    "We will mostly use `DataFrame` objects instead of `Series` objects. But it's important to know what `Series` objects are because that's what we'll end up with whenever we extract a single column from a dataframe.\n",
    "\n",
    "##### More Information\n",
    "* [Pandas Data Structures](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Selecting Data within Pandas Dataframes\n",
    "Pandas provides an immense number of ways to select and extract data from a dataframe, many more than can be covered in this class. Check out the [official Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) to see for yourself. The Pandas documentation often refers to selecting data as *indexing*, which may seem strange at first. Think about it like this - to extract the fourth item from a list called `mylist`, we put the number 3 in square brackets: `fourth_num = mylist[3]`. The number 3 is the index position of the lists fourth element of the list. We're selecting a value from the list by passing an index to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Selecting a Single Column\n",
    "Select a single column by using a dictionary-style notation. Place the column name in quotes and square brackets. This technique works for all columns regardless of their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a single column\n",
    "space_df[\"Status Mission\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary style also works with a string variable that contains the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_var = \"Status Rocket\"\n",
    "space_df[col_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Selecting Part of a Single Column\n",
    "We can select one or more rows from a single column the same way we select portions of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df.Detail[100:105] # Detail is the name of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Selecting Multiple Columns\n",
    "Multiple columns can be selected by passing a list of column names within square brackets. We can even change the column order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df[[\"Location\", \"Company Name\", \"Status Mission\"]] \n",
    "# Notice how with more than 1 specified column name, you need 2 sets of square brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Selecting Rows\n",
    "You might be tempted to select a row from a `DataFrame` the same way we select an element from a list. Resist that temptation, it won't work. Use `.loc[]` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting part of a DataFrame with the `.loc()` function\n",
    "space_df.loc[0:3, \"Company Name\":\"Datum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `.loc` function, pass two elements within square brackets, separated by a comma. The first element specifies what rows are selected, and the second specifies what columns are selected. List-style slice notation can be used to select ranges of rows and columns. In the example above, we selected rows 0 through 3 and columns \"Company Name\" through \"Datum\".\n",
    "\n",
    "One difference between Pandas dataframe slice notation differs and Python list notation is that for Python lists, the slice does NOT return the final element. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python list slices include all elements up to but NOT including the final\n",
    "# element in the slice\n",
    "# Will return 3 list items\n",
    "tens = [0, 10, 20, 30, 40, 50, 60]\n",
    "tens[0:3]  # The fourth element, 30, is not returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slices in DataFrames will include the final element of the slice\n",
    "# Returns 4 rows and 4 columns\n",
    "space_df.loc[0:3, \"Detail\":\"Status Mission\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows and columns need not be contiguous. We can pass in lists of row indices and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df.loc[[100, 200, 300, 400], [\"Detail\", \"Datum\", \"Rocket\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  More Information\n",
    "* [Selecting a Subset of a Dataframe (short intro)](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/03_subset_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Pandas Indexing Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex III.3\n",
    "Display the datums and company names for rows 1318, 2976, and 4131."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex III.4\n",
    "Display the final 10 rows of the *Detail* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Searching Within a Dataframe\n",
    "Being able to extract data by row and column numbers is helpful at times, but it requires that we know the exact location of the data we want. In large dataframes with thousands of rows, we typically do NOT know the exact location. Fortunately, Pandas provides many techniques for searching within a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Boolean Indexing\n",
    "Boolean indexing is a powerful technique for filtering dataframes. Check out the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for Specific Data in Dataframe\n",
    "# How many successful space launches were conducted by the U.S. Navy?\n",
    "space_df[space_df[\"Company Name\"] == \"US Navy\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax in for filtering the dataframe to only US Navy launches may look strange. It will make sense once we know more about how Pandas works. First, let's see what the expression `space_df[\"Company Name\"] == \"US Navy\"` does by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expression: space_df[\"Company Name\"] == \"US Navy\"')\n",
    "print(\"Type of object returned by expression:\", type(space_df[\"Company Name\"] == \"US Navy\"))\n",
    "print(\"Object contents:\")\n",
    "space_df[\"Company Name\"] == \"US Navy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression returned `Series` object of Boolean values. The Series has a length of 4,324 items, which is the same as the number of rows in the dataframe. That's suspicous...\n",
    "\n",
    "In the expression, we're taking the `Series` object returned by the expression `space_df[\"Company Name\"]` and we're comparing it to the string \"US Navy\". Pandas then checks every single element (all 4,324) to the string \"US Navy\", generating a value of True if the value is equal to \"US Navy\" and False otherwise. This action generates 4,234 True or False values, which Pandas returns as a `Series`. An operation that is repeated on every single element of an array-like object (e.g., list, array, Series) is called an element-wise or vectorized operation. One of the benefits of using Pandas is it is capable of many element-wise operations. Not having to write a `for` loop is convenient and makes code more concise. Also, element-wise operations are often faster than operations that use `for` loops.\n",
    "\n",
    "When we pass a `Series` of Boolean values to the dataframe by placing it in square brackets, Pandas will return another dataframe with only the rows that correspond to values of True in the Boolean series. Let's experiment. The following cell generates a Boolean series that is the same length as `space_df`, with every value set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series where every element is equal to False\n",
    "bseries = pd.Series([False] * len(space_df))\n",
    "bseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll bass the series to the space_df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass series to space_df\n",
    "space_df[bseries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, no dataframe rows were returned, because all `bseries` elements are false. Let's change a few of the elements to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bseries[1318] = True\n",
    "bseries[1595] = True\n",
    "bseries[2046] = True\n",
    "bseries[2907] = True\n",
    "bseries[2017] = True\n",
    "space_df[bseries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison operators we are not limited to `==`. We can also use `<=`, `>=`, `<`, `>`, and `!=`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compound Boolean Indexing\n",
    "Compound Boolean exressions are also allowed. See the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for Specific Data in Dataframe\n",
    "# How many unsuccessful space launches were conducted by the U.S. Navy?\n",
    "space_df[(space_df[\"Company Name\"] == \"US Navy\") & (space_df[\"Status Mission\"] == \"Success\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the Boolean indexing syntax uses different Boolean operators than standard Python code. Instead of `and`, Boolean indexing uses `&`. Instead of `or` and `not`, Boolean indexing uses `|` and `~` respectively. Also, each part of a compound Boolean expression *must* be grouped with parentheses, or the expression will generate an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isin()` method is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df[space_df[\"Company Name\"].isin([\"SpaceX\", \"Blue Origin\", \"ULA\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The `isin()` Method\n",
    "The `.isin()` method returns `True` if the value is equal to any of the elements in the list that is passed as a parameter. We could get the same results with a long compound Boolean statement with many `|` (i.e., *or*) operators, but using `.isin()` is much easier. The result can be negated with the `~` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df[~space_df[\"Company Name\"].isin([\"SpaceX\", \"Blue Origin\", \"ULA\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Boolean Indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. *NaN* Values\n",
    "By now you've noticed that the value *Nan* appears frequently. It stands for *not a number* and is used to represent missing data. We can use the `.notna()` method to filter out rows with *NaN* values. Suppose we only want rows with no missing data in the *Rocket* column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df[space_df[\"Rocket\"].notna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, we can use the `.isna()` method to select rows that contain *NaN*.\n",
    "\n",
    "##### More Information\n",
    "* [Pandas documentation on missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Using the Query Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.query()` method can also be used to extract specific rows from a dataframe. Users pass a query string to the method instead of a Boolean series object. Our queries will be more effective if we make a couple tweaks on the space dataframe first. All dataframe columns are currently strings. The following cell will convert two of the columns to different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Rocket and Datum columns to numeric and datetime data types\n",
    "space_df[\"Rocket\"] = space_df[\"Rocket\"].astype('float32')\n",
    "space_df[\"Datum\"] = pd.to_datetime(space_df[\"Datum\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell uses the `.query()` method to find all launches by NASA where the mission cost more than $1,000,000,000 (The *Rocket* column contains the cost of the mission, in millions of dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate search technique using the `query()` method\n",
    "space_df.query(\"`Company Name` == 'NASA' and Rocket > 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query strings are more intuitive and less verbose than Boolean indexing. They can also be faster on large dataframes. They do have a few quirks:\n",
    "* The query string specifies criteria that each column name must meet in order to be included in the resulting dataframe. If column names that contain spaces or other special characters must be enclosed in backticks, like `Company Name`. Note that a backtick (\\`) is not the same as a single quote ('). The backtick key on your keyboard should be near th upper left corner, whereas the single quote is next to the ENTER key.\n",
    "* String values that appear in the query, like 'NASA', must be quoted. We use single quotes to denote strings in our example because the entire query string is enclosed in double quotes. But we could swap the single and double quotes --  '`Company Name` == \"NASA\" and Rocket > 1000' would work just as well as a query string.\n",
    "* Query strings uses `and`, `or`, and `not` as logical operators.\n",
    "* Comparison operators in query strings are as expected: `==`, `<=`, `>=`, `<`, `>`, and `!=`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the query was embedded in a function, with the *Company Name* passed in as a parameter. We can include a variable in the query string using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_launches(company):\n",
    "    return space_df.query(\"`Company Name` == @company and Rocket > 1000\")\n",
    "\n",
    "get_launches(\"NASA\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.query()` method accepts `in` and `not in` operators, similar to Boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\"SpaceX\", \"Blue Origin\", \"ULA\"]\n",
    "space_df.query(\"`Company Name` in @companies\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Pandas user guide section on the `.query()` method](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#the-query-method).\n",
    "* [Query method API reference](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Boolean Indexing Exercises and the Query Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.5\n",
    "The `grads` dataframe contains information on different college majors. How many majors are there in the *Engineering* category? How many in *Biology and Life Science*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.5\n",
    "grads = pd.read_csv(\"recent-grads.csv\")     # Leave this line alone\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.6\n",
    "Display the first 20 rows and only the *Major*, *Total*, *Unemployment_rate*, and *Median* columns of the grads dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.sort_values()` method to sort the `grads` dataframe by *Median* in descending order and display the first five rows. Which major has the highest median income? Refer to the [Dataframe.sort_values documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html?highlight=sort_values#pandas.DataFrame.sort_values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.8\n",
    "Use Boolean indexing to extract majors in the categories of *Business*, *Physical Sciences*, or *Arts* that have greater than 2500 respondents (*Total* column). Don't forget the parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.9\n",
    "Use the `.query()` method to identify majors for which the share of women is greater than 50% and have a median salary greater $50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Column Datatypes\n",
    "Every column in a Pandas `DataFrame` has a specific datatype. For the sake of demonstration, we will reload the space dataframe from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload space dataframe\n",
    "space_df2 = pd.read_csv(\"space.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the datatype of each column with the `.dtypes` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Datatypes\")\n",
    "space_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type *object* is Pandas' datatype for a string. You might think that the *Rocket* column should be a numeric datatype. Pandas decided it was a string because several entries are using a comma as a thousands separator, e.g., `1,160`. The `.read_csv` method has an argument that will help Pandas read the *Rocket* column as a string, in spite of the commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload space dataframe, with commas as thousands separator\n",
    "space_df2 = pd.read_csv(\"space.csv\", thousands=\",\")\n",
    "\n",
    "print(\"Column Datatypes\")\n",
    "space_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Rocket* column is now a floating point number. That's more like it.\n",
    "\n",
    "But what about the Datum column? We can't do date calculation on that column because Pandas is considering it to be a string. We can convert the column to a special datetime object with the `pandas.to_datetime()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Datum to a datetime object.\n",
    "space_df2[\"Datum\"] = pd.to_datetime(space_df2[\"Datum\"], utc=True)\n",
    "print(\"Column Datatypes\")\n",
    "space_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the column is converted to a datetime object, we can access parts of the date using the `.dt` accessor. For example, to get an integer representing the month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df2.Datum.dt.month.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is `.astype()`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df2.Rocket.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the numbers in the *Rocket* column to 32-bit numbers (from 64-bit numbers) to save space. Other common datatypes include \"int32\", \"int64\", \"unint32\" (unsigned, meaning only positve numbers are allowed), and \"boolean\".\n",
    "\n",
    "##### More Information\n",
    "* [Pandas Datatypes](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Datatype Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.10\n",
    "Using the `grads` dataframe, convert the *Median* column's datatype to `uint32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Statistics Functions\n",
    "Pandas has several functions for extracting summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum mission cost in $millions:\\t\", space_df.Rocket.max())\n",
    "print(\"Mean mission cost in $millions:\\t\\t\", space_df.Rocket.mean())\n",
    "print(\"Standard Deviation mission cost:\\t\", space_df.Rocket.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Getting Started Tutorial on Summary Satistics](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/06_calculate_statistics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Statistics Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.11\n",
    "Use the `.min()` and `max()` methods to determine which majors have the lowest and highest unemployment rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.12\n",
    "Repeat exercise III.11, but only consider majors with more than 2,000 respondents (*Total* column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Dataframe Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting started with Indexes\n",
    "Indexes are an important concept in Pandas. To understand indexes, we'll use a dataframe that contains match data from the 2019 Pacific Northwest district competition at Glacier Peak High School in Snohomish, WA. First we have to load the dataframe from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a datframe from a pickle file.\n",
    "import pickle\n",
    "with open(\"matches.pickle\", \"rb\") as pfile:\n",
    "    matches = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python Standard Library includes a *pickle* module that allows us to save any Python object to a file and load it back into Python at a later time. Here are the first few rows from the dataframe that was contained in the *matches.pickle* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant difference between the space and matches dataframes, besides the fact that they have different columns. Let's look at the first few rows of the space dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The far left column of the space dataframe contains integers, with the first row having integer 0, the second row having integer 1, and so on. They appear to be row numbers. Unlike all other columns, they are displayed using a bold font.\n",
    "\n",
    "The matches dataframe also has a column on the far left that is displayed using a bold font, but it does not contain integers. It contains a string with a code that identifies the match, formatted like this: *{year}{event_code}{comp_level_code}m{match_number}*. The column also has a name: *key*. By the way, the syntax of the *key* values has nothing to do with Pandas. This data was retrieved from [The Blue Alliance](https://www.thebluealliance.com/) website, which uses a this key value to uniquely identify every FRC match that occurs at every competition throughout the world.\n",
    "\n",
    "The column on the far left is a special column. It is called the *index* and it can contain integers, strings, data values or other data types. If we don't tell Pandas how to create the index when we create a dataframe, Pandas will create an integer index, where each index value is the row number. But when the matches dataframe was created, Pandas was told to use *The Blue Alliance's* match key for the index. (If you would like to see how the matches datframe was created, check out the *convert_json_to_df.ipynb* notebook in the *setup* subfolder.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Indexes are Objects\n",
    "Here is one way to think about indexes: just like every column has a unique name, every row has a unique name. The index is a column that contains the row names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing column and row names for the matches dataframe.\n",
    "print(\"Matches Dataframe Column Names:\\n\", matches.columns)\n",
    "print(\"\\nMatches Dataframe Row Names (first 10):\\n\", matches.index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look closely at the output from the cell above. First of all, we can easily view all column or row names with the `DataFrame.columns` and `DataFrame.index` attributes. But look closer. See how the printed output starts with `Index([...`? The columns and index are themselves an object with a special datatype. We'll prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index object types\n",
    "print(\"Index object type:\\t\\t\", type(matches.index))\n",
    "print(\"Columns object type:\\t\\t\", type(matches.columns))\n",
    "print(\"Object type of a regular column:\", type(matches.red_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the index and columns are the same object type: `Index`, which is different than the object type of a regular column like *red_score* (object type is `Series`). This means the index will behave differently than a regular column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Reason for Having Indexes - The `.loc()` Method\n",
    "Why do Pandas dataframes have an index? The size of a Pandas dataframe is limited only by the amount of memory on your computer.  Pandas dataframes can have millions of rows -- that's not hyperbole. The designers of Pandas wanted to be able to extract data from dataframes quickly, regardless of the size of the dataframe. The `Index` objects make that possible. If we extract data using index values and column names, we can extract data just as quickly from large datasets as we can from small datasets.\n",
    "\n",
    "There is a caveat. For indexing (i.e., extracting data) to be fast on large dataframes, each row and column must have a unique index value. Pandas will allow duplicate index values, but some operations will be slower, and there could be other problems. The best practice is to ensure each row and column has a unique index value. Your choice of index will depend on the data and how you want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extracting Data with Index Values\n",
    "We've already used the method for extracting data with index values. It's the `.loc` method back in section D.4. Here's a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_df.loc[0:3, \"Company Name\":\"Datum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use `.loc()` on the space dataframe, it appears that `.loc()` uses row numbers. But that's because the index for the space dataframe uses a simple integer index. The same technique will *not* work on the matches dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code generates an error\n",
    "matches.loc[0:3, \"red1\":\"blue3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom of the long error message, you should see a statement indicating that Pandas is unable to use integers to index this dataframe. The `.loc()` method requires us to pass index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of teams in quarterfinal matches.\n",
    "matches.loc[\"2020wasno_qf1m1\":\"2020wasno_qf4m3\", \"red1\":\"blue3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [The loc Function](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#selection-by-label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Extracting Data with Row and Column Numbers -- Using `.iloc()`\n",
    "There may be times when you don't care about the index or column name. For example, you just want the value from the 5th column of the 17th row. Pandas makes that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting value from specific row and column\n",
    "# Remember, 1st row and 1st column are at index 0\n",
    "matches.iloc[16, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.iloc()` method works similarly to `.loc()`, but it only takes integer row and column numbers. Here's another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.iloc[30:35, :-9:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.iloc()` method accepts list-style slices. In the example above, we selected a range of rows and the last eight columns, but in reverse order.\n",
    "\n",
    "##### More Information\n",
    "* [The iloc Function](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#selection-by-position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Index Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.13\n",
    "For the `grads` dataframe, use the `.set_index()` method to make the *Major_code* column the index. Refer to the [documentation for the `set_index()` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html?highlight=set_index#pandas.DataFrame.set_index). Either assign the modified dataframe to a new variable, or use the *inplace* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.14\n",
    "With the modified `grads` dataframe from exercise III.13, sort the dataframe in ascending order by the index. Use the `.sort_index()` method ([see the documentation here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_index.html?highlight=sort_index#pandas.DataFrame.sort_index)). Next, extract all columns from *Major_code* to *Employed*, but limit rows to those with major codes between 4000 and 4999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H. Making your own DataFrames from Scratch\n",
    "The two most common ways to construct a `DataFrame` object from core Python objects are the column method and the row method.\n",
    "\n",
    "For the column method, you pass a dictionary to the `Pandas.DataFrame` constructor.\n",
    "* Each key of the dictionary is a column name.\n",
    "* Each value is a list of values that will go in the corresonding column.\n",
    "* Each list must be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column method for creating a dataframe\n",
    "x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the row method, you pass a list of dictionaries to the `Pandas.DataFrame` constructor.\n",
    "* Each dictionary corresponds to one row of the dataframe.\n",
    "* Each dictionary key is a column name and each dictionary value will be the value for the corresponding row and column.\n",
    "* This method is more fault tolerant. If a dictionary is missing a column value, Pandas will not throw an error, but will insert a `NaN` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = pd.DataFrame([{\"x\": 10, \"y\": 30},\n",
    "                   {\"x\": 20, \"y\": 40, \"z\": 100},\n",
    "                   {\"x\": 30, \"y\": 50}])\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Series and Dataframe Creation](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html#object-creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Modifying Data in Dataframes\n",
    "So far we've only been reading data from Pandas DataFrames. But we can change dataframes. They are mutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also assign a dict to a row of a DataFrame\n",
    "x.iloc[1] = {'x': 9, 'y': 99}\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.append({'x': 5, 'y': 9}, ignore_index = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['z'] = [1, 2, 3, 4]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5], 'z': [45, 45, 56]})\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can append 2 dataframes together\n",
    "x = x.append(z)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dataframe Creation Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.15\n",
    "Use list comprehensions to create three lists each with 20 numbers. The first list should contain integers ranging from 0 to 19. The second should contain the squares of the numbers in the first list, and the third list should contain the cubes. Create a dataframe with three columns, where each column contains one of the lists. Use descriptive, logical names for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J. Grouping and Aggregating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we've been using only a fraction of Pandas' capabilities. Pandas Pandas can also be used to transform and analyze data.\n",
    "\n",
    "Suppose we want to know the average alliance score for the entire competition. Since scores are contained in either the *blue_score* or *red_score* column. We could use the `.mean()` method to calculate the average of each column and then average those two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean of the red and blue score columns\n",
    "print(\"Blue alliance mean score:\\t\",\n",
    "      round(matches.blue_score.mean(), 1))\n",
    "print(\"Red alliance mean score:\\t\", round(matches.red_score.mean(), 1))\n",
    "print(\"Overall mean score:\\t\\t\",\n",
    "      round((matches.red_score.mean() + matches.blue_score.mean()) / 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas, there is usually more than one way to do something, and this example is no exception. For example, we could also add a column to the dataframe that contains the mean of of the red and blue alliance scores for each match, and just take the mean of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new mean_score column\n",
    "matches[\"mean_score\"] = (matches[\"red_score\"] + matches[\"blue_score\"]) / 2    # line 1\n",
    "print(\"Overall mean score:\\t\", round(matches.mean_score.mean(), 1)) # line 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay close attention to line 1 -- there is a lot going on in that line.\n",
    "* First, we're able to create a new column named *mean_score* simply by referencing the column and assigning something to it, e.g., `matches[\"mean_score\"] = ...`.\n",
    "* Line 1 is also using element-wise calculations. This is an important concept, so we'll cover it in detail.\n",
    "    * The expressions `matches[\"red_score\"]` and `matches[\"blue_score\"]` both return a Pandas `Series` object.\n",
    "    * Mathematical operators like `+` behave differently with `Series` objects than they behave with other data types, such as Python lists. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using '+' with Python lists and Pandas Series\n",
    "list1 = [1, 2, 3]\n",
    "list2 = [10, 20, 30]\n",
    "print(\"Using '+' with Python lists:\\t\", list1 + list2)\n",
    "series1 = pd.Series([1, 2, 3])\n",
    "series2 = pd.Series([10, 20, 30])\n",
    "series3 = series1 + series2\n",
    "print(\"\\nUsing '+' with Pandas series:\")\n",
    "series3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding two Python lists concatenates the two lists into a longer list. But adding two `Series` objects causes the first elements of each series to be summed, as well as the second elements, etc. This is what we mean by element-wise operations.\n",
    "\n",
    "So when we added `matches[\"red_score\"]` and `matches[\"blue_score\"]` and divided the result by two, for every row in the `matches` dataframe, we took the red score and the blue score, added them together, divided the sum by two, and put the result in a new column called *mean_score*. The following cell shows the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[[\"blue_score\", \"red_score\", \"mean_score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we were interested in the average score for each level of competition. That is, suppose we wanted an average score for qualification matches, another average score for quarter-finals, another for semi-finals, and so on. We could use the indexing techniques to extract a dataframe containing only the rows corresponding to each level, and then calculate a mean from each separate dataframe, but that would be a lot of work. It's easier to do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(\"comp_level\").agg({\"mean_score\": \"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is actually quite remarkable. One line of code split our data into groups by competition level and then calculated a mean score for each level.\n",
    "\n",
    "First, the `groupby()` method created a Pandas `GroupBy` object, where rows are split into groups based on the content of the *comp_level* column. We can extract the individual groups with the `.get_group()` method. For example, the following line extracts the finals matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(\"comp_level\").get_group(\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `.agg()` method calculates the mean of the values in each group's *mean_score* column. The string \"mean\" refers to an aggregate function, which is a function that calculates a single number from many different numbers. Pandas provides numerous aggregate functions, including *sum*, *size*, *count*, *std* (standard deviation), *var* (variance), *min*, and *max*. We can add additional columns that calculate different summary statistics for each group. The following example adds a column with the earliest match start time for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby(\"comp_level\").agg({\"actual_time\": \"min\", \"mean_score\": \"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More Information\n",
    "* [Groub by: Split-Apply-Combine](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Aggregation Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ex III.16\n",
    "Using the `grads` dataframe, calculate the average unemployment rate and the standard deviation of the median salaries for each category of majors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex III.16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Quiz\n",
    "Answer the following questions by typing the answers as comments in the code block below each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#1.** Of the data file formats we have studied so far, which one can be viewed in a standard text editor *and* can contain nested data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2.** Tab separated files (TSV) are very similar to comma separated files. Tab characters, '\\t' are used to separate columns instead of commas. This format can be useful if the data itself contains commas.\n",
    "\n",
    "Review the [documentation for the Python Standard Library's `csv` module](https://docs.python.org/3/library/csv.html?highlight=csv#module-csv). Can this module be used for reading tab TSV files? If so, write out the code that could be used to load a TSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3.**  This code will throw an error. Why? How do we fix it?\n",
    "\n",
    "```python\n",
    "space_df[\"Company Name\", \"Datum\", \"Detail\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#4.** What are two differences between a Python list and a Pandas Series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#5.** What is the difference between the `.loc()` and `.iloc()` methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#6.** When are tick marks required when using the `.query()` methods? How are tick marks different than quotation marks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#7.** Suppose we have a dataframe `small_df` with two numeric columns, *col1* and *col2*.\n",
    "\n",
    "|  |col1|col2|\n",
    "|--|----|----|\n",
    "|0 |1   |2   |\n",
    "|1 |10  |20  |\n",
    "|2 |100 |NaN |\n",
    "\n",
    "Suppose we run the following line of code?\n",
    "```python\n",
    "small_df[\"col3\"] = small_df[\"col1\"] * small_df[\"col2\"]\n",
    "```\n",
    "What values will *col3* contain? Review the [user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#calculations-with-missing-data) to see how *NaN* values are handled within mathematical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#8.** Many Pandas methods, including several used earlier in this notebook, have an *inplace* parameter. What does this parameter do? Review the API documentation for some of the functions that we have used if you are not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#9.** We discussed two different techniques for creating a Pandas dataframe from Python data structures. One technique used a dictionary of lists, and the other used a list of dictionaries. Which one is the column-centric approach, and which is the row-centric approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#10.** Review the *`setup/convert_json_to_df.ipynb`* notebook. This notebook was used to create the matches dataframe that we used in this session. The dataframe was created using data in the *`setup/matches.json`* file. Review the notebook and JSON file and try to figure out how it works. Refer to Python or Pandas documentation if any of the syntax looks unfamiliar.\n",
    "\n",
    "There is a line of code in the notebook that merges two dataframes. Copy the line of code into your answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#11.** The answer to question #10 contains a method that takes more than one argument. Explain what each argument does. You can easily find the documentation for the method by typing it into the search field on the Pandas documentation website (upper left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Save Your Work\n",
    "Once you have completed the exercises, save a copy of the notebook outside of the git repository (outside of the *pyclass_frc* folder). Include your name in the file name. Follow instructions from your instructor to get feedback on your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Concept and Terminology Review\n",
    "You should be able to define the following terms or describe the concept.\n",
    "* CSV files\n",
    "* TSV files\n",
    "* The csv module from the Python Standard Library\n",
    "* Creating dataframes, including both the row and column approach\n",
    "* Pandas `DataFrame` and `Series` datatypes\n",
    "* Pandas `.head()` and `.tail()` methods\n",
    "* `Dataframe.shape` attribute\n",
    "* Selecting dataframe columns\n",
    "* Selecting rows from a Series\n",
    "* Pandas `.loc` and `.iloc` methods\n",
    "* Boolean indexing\n",
    "* Pandas `.query()` method\n",
    "* Element-wise operations\n",
    "* The `.isin()` and `isna()`, and `.notna()` methods\n",
    "* *NaN* values\n",
    "* Column datatypes\n",
    "* Pandas `.to_datetime()` and `.astype()` methods\n",
    "* Pandas statistical functions\n",
    "* Pandas Indexes\n",
    "* The `DataFrame.set_index()` method\n",
    "* Modifying data in dataframes\n",
    "* Adding new columns to a dataframe\n",
    "* Grouping and Aggregating data\n",
    "* Sorting the dataframe by a column or by the index (`.sort_index()` and `sort_values()` methods)\n",
    "* Merging Pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](../../index.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
